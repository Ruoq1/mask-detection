import os
import cv2
import numpy as np
import shutil
import xml.etree.ElementTree as ET
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import albumentations as A

# è®¾ç½®è·¯å¾„
DATA_DIR = "data"
IMAGE_DIR = os.path.join(DATA_DIR, "images")
ANNOTATION_DIR = os.path.join(DATA_DIR, "annotations")
YOLO_LABELS_DIR = os.path.join(DATA_DIR, "labels")
OUTPUT_DIR = os.path.join(DATA_DIR, "preprocessed")

# åˆ›å»ºç›®å½•
os.makedirs(YOLO_LABELS_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ç»Ÿä¸€å›¾ç‰‡å¤§å°
IMG_SIZE = 640

# PASCAL VOC ç±»åˆ«æ˜ å°„åˆ° YOLO æ ¼å¼
CLASS_MAPPING = {"with_mask": 0, "without_mask": 1, "mask_weared_incorrect": 2}

# 1ï¸âƒ£ è¯»å–æ‰€æœ‰å›¾ç‰‡ï¼ˆè‡ªåŠ¨åŒ¹é…å¤§å°å†™ï¼‰
def load_images(image_dir):
    if not os.path.exists(image_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {image_dir}")
        return []
    images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    if len(images) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶æ ¼å¼ï¼")
    return images

# 2ï¸âƒ£ è‡ªåŠ¨åŒ¹é…æœ€æ¥è¿‘çš„æ–‡ä»¶åï¼ˆé˜²æ­¢æ‹¼å†™æˆ–å¤§å°å†™é—®é¢˜ï¼‰
def find_closest_filename(image_dir, target_filename):
    """ åœ¨ç›®å½•ä¸­æ‰¾åˆ°æœ€æ¥è¿‘çš„æ–‡ä»¶åï¼ˆå¿½ç•¥å¤§å°å†™å’Œæ‹¼å†™é”™è¯¯ï¼‰ """
    files = os.listdir(image_dir)
    lower_files = {f.lower(): f for f in files}  # ç”Ÿæˆå°å†™æ–‡ä»¶åçš„æ˜ å°„
    return lower_files.get(target_filename.lower(), None)

# 3ï¸âƒ£ è°ƒæ•´å›¾ç‰‡å¤§å°ï¼ˆæ”¯æŒè‡ªåŠ¨åŒ¹é…æ–‡ä»¶åï¼‰
def resize_images(image_path, output_path, size=IMG_SIZE):
    image_dir = os.path.dirname(image_path)
    image_name = os.path.basename(image_path)

    # è‡ªåŠ¨åŒ¹é…æœ€æ¥è¿‘çš„æ–‡ä»¶å
    corrected_filename = find_closest_filename(image_dir, image_name)
    if corrected_filename:
        image_path = os.path.join(image_dir, corrected_filename)
    else:
        print(f"âŒ æ–‡ä»¶ {image_name} ä¸å­˜åœ¨")
        return

    img = cv2.imread(image_path)
    if img is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return
    
    img = cv2.resize(img, (size, size))
    cv2.imwrite(output_path, img)
    print(f"âœ… å·²ä¿å­˜: {output_path}")

# 4ï¸âƒ£ è§£æ PASCAL VOC XML å¹¶è½¬æ¢ä¸º YOLO æ ¼å¼
def convert_voc_to_yolo(xml_file, img_width, img_height):
    tree = ET.parse(xml_file)
    root = tree.getroot()
    yolo_labels = []

    for obj in root.findall("object"):
        class_name = obj.find("name").text
        class_id = CLASS_MAPPING[class_name]

        bbox = obj.find("bndbox")
        xmin, ymin, xmax, ymax = map(int, [
            bbox.find("xmin").text, bbox.find("ymin").text,
            bbox.find("xmax").text, bbox.find("ymax").text
        ])

        # å½’ä¸€åŒ–è¾¹ç•Œæ¡†
        x_center = (xmin + xmax) / 2 / img_width
        y_center = (ymin + ymax) / 2 / img_height
        width = (xmax - xmin) / img_width
        height = (ymax - ymin) / img_height

        yolo_labels.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

    return yolo_labels

# 5ï¸âƒ£ å¤„ç†æ‰€æœ‰æ•°æ®
def process_dataset():
    images = load_images(IMAGE_DIR)

    for img_name in tqdm(images, desc="Processing images"):
        image_path = os.path.join(IMAGE_DIR, img_name)
        xml_path = os.path.join(ANNOTATION_DIR, img_name.replace(".jpg", ".xml").replace(".png", ".xml"))

        if not os.path.exists(xml_path):
            continue  # å¦‚æœæ²¡æœ‰å¯¹åº”çš„ XML æ ‡æ³¨ï¼Œè·³è¿‡

        # è¯»å–åŸå§‹å›¾ç‰‡å¤§å°
        img = cv2.imread(image_path)
        if img is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
            continue
        h, w, _ = img.shape

        # å¤„ç†å›¾ç‰‡
        resized_image_path = os.path.join(OUTPUT_DIR, img_name)
        resize_images(image_path, resized_image_path)

        # è½¬æ¢æ ‡ç­¾
        yolo_labels = convert_voc_to_yolo(xml_path, w, h)
        label_file = os.path.join(YOLO_LABELS_DIR, img_name.replace(".jpg", ".txt").replace(".png", ".txt"))

        with open(label_file, "w") as f:
            f.write("\n".join(yolo_labels))

# 6ï¸âƒ£ åˆ’åˆ†æ•°æ®é›†
def split_dataset():
    images = load_images(OUTPUT_DIR)
    print(f"ğŸ” æ€»å›¾ç‰‡æ•°: {len(images)}")

    if len(images) == 0:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥ `OUTPUT_DIR`")
        return
    
    train_imgs, test_imgs = train_test_split(images, test_size=0.2, random_state=42)
    val_imgs, test_imgs = train_test_split(test_imgs, test_size=0.5, random_state=42)

    print(f"âœ… è®­ç»ƒé›†: {len(train_imgs)}, éªŒè¯é›†: {len(val_imgs)}, æµ‹è¯•é›†: {len(test_imgs)}")

    for split, img_list in zip(["train", "val", "test"], [train_imgs, val_imgs, test_imgs]):
        split_dir = os.path.join(DATA_DIR, split)
        os.makedirs(split_dir, exist_ok=True)

        for img in img_list:
            src_img = os.path.join(OUTPUT_DIR, img)
            dst_img = os.path.join(split_dir, img)

            src_label = os.path.join(YOLO_LABELS_DIR, img.replace(".jpg", ".txt").replace(".png", ".txt"))
            dst_label = os.path.join(split_dir, img.replace(".jpg", ".txt").replace(".png", ".txt"))

            if os.path.exists(src_img):
                shutil.move(src_img, dst_img)
            else:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å›¾ç‰‡: {src_img}")

            if os.path.exists(src_label):
                shutil.move(src_label, dst_label)
            else:
                print(f"âš ï¸ æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶: {src_label}")

# 7ï¸âƒ£ è¿è¡Œæ•°æ®é¢„å¤„ç†
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    process_dataset()   # å¤„ç†å›¾ç‰‡ & æ ‡ç­¾
    split_dataset()     # åˆ’åˆ†æ•°æ®é›†
    print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
